{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据并划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 鸢尾花数据集\n",
    "def iris_dataloader():\n",
    "    dataset = pd.read_csv(\"iris.data\", names=[\"萼片长度\", \"萼片宽度\", \"花瓣长度\", \"花瓣宽度\",\"物种\"])\n",
    "    # 按照四比一划分训练集和测试集\n",
    "    train_set, test_set = train_test_split(dataset, test_size=0.2)\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 成人数据集\n",
    "def adult_dataloader():\n",
    "    names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"]\n",
    "    dataset = pd.read_csv(\"adult.data\", names=names, nrows=2000)\n",
    "    # 按照四比一划分训练集和测试集\n",
    "    train_set, test_set = train_test_split(dataset, test_size=0.2)\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算基尼系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算基尼系数\n",
    "def gini(counts):\n",
    "    total = sum(counts)\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    return 1 - sum((count / total) ** 2 for count in counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算加权基尼系数\n",
    "def weighted_gini(counts_list):\n",
    "    total = sum(sum(counts) for counts in counts_list)\n",
    "    return sum((sum(counts) / total) * gini(counts) for counts in counts_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 选取属性进行数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以某一个离散特征作为划分依据的话，计算这个离散特征下最优的划分方式\n",
    "def lisan_feature(dataset, feature):\n",
    "    choices = dataset[feature].unique()\n",
    "    best_choice = None\n",
    "    best_pass_subset = None\n",
    "    best_refuse_subset = None\n",
    "    min_gini = 1.0\n",
    "    \n",
    "    for choice in choices:\n",
    "        # 根据“特征是否是这个值”划分为两个子集\n",
    "        pass_subset = dataset[dataset[feature] == choice]\n",
    "        refuse_subset = dataset[dataset[feature] != choice]\n",
    "\n",
    "        # 计算加权平均基尼系数\n",
    "        pass_counts = pass_subset.iloc[:, -1].value_counts()\n",
    "        refuse_counts = refuse_subset.iloc[:, -1].value_counts()\n",
    "        gini = weighted_gini([pass_counts, refuse_counts])\n",
    "\n",
    "        # 如果基尼系数小于记录的数据则进行更新\n",
    "        if gini < min_gini:\n",
    "            best_choice = choice\n",
    "            best_pass_subset = pass_subset\n",
    "            best_refuse_subset = refuse_subset\n",
    "            min_gini = gini\n",
    "\n",
    "    return best_choice, best_pass_subset, best_refuse_subset, min_gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以某一个连续值的特征作为划分依据的话，计算最优划分的方式\n",
    "def lianxu_feature(dataset, feature):\n",
    "    unique_values = dataset[feature].unique()\n",
    "    thresholds = (unique_values[:-1] + unique_values[1:]) / 2\n",
    "    best_threshold = None\n",
    "    best_less_subset = None\n",
    "    best_more_subset = None\n",
    "    min_gini = 1.0\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        # 根据“取值是否小于该阈值”划分为两个子集\n",
    "        less_subset = dataset[dataset[feature] < threshold]\n",
    "        more_subset = dataset[dataset[feature] >= threshold]\n",
    "\n",
    "        # 计算加权平均基尼系数\n",
    "        less_counts = less_subset.iloc[:, -1].value_counts()\n",
    "        more_counts = more_subset.iloc[:, -1].value_counts()\n",
    "        gini = weighted_gini([less_counts, more_counts])\n",
    "\n",
    "        # 如果基尼系数小于记录的数据则进行更新\n",
    "        if gini < min_gini:\n",
    "            best_threshold = threshold\n",
    "            best_less_subset = less_subset\n",
    "            best_more_subset = more_subset\n",
    "            min_gini = gini\n",
    "\n",
    "    return best_threshold, best_less_subset, best_more_subset, min_gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选取特征进行划分\n",
    "def choose_feature(dataset):\n",
    "    features = dataset.columns[:-1]\n",
    "    best_feature = None\n",
    "    best_choice = None\n",
    "    best_threshold = None\n",
    "    best_left_subset = None\n",
    "    best_right_subset = None\n",
    "    min_gini = 1.0\n",
    "    \n",
    "    for feature in features:\n",
    "        # 如果一个特征只有一个值，你们就不能选择来作为划分依据，跳过\n",
    "        if len(dataset[feature].unique()) == 1:\n",
    "            continue\n",
    "\n",
    "        # 离散\n",
    "        if dataset[feature].dtype == object:\n",
    "            choice, left_subset, right_subset, gini = lisan_feature(dataset, feature)\n",
    "            threshold = None\n",
    "\n",
    "        # 连续\n",
    "        else:\n",
    "            threshold, left_subset, right_subset, gini= lianxu_feature(dataset, feature)\n",
    "            choice = None\n",
    "\n",
    "        # 如果基尼系数小于记录的数据则进行更新\n",
    "        if gini < min_gini:\n",
    "            best_feature = feature\n",
    "            best_choice = choice\n",
    "            best_threshold = threshold\n",
    "            best_left_subset = left_subset\n",
    "            best_right_subset = right_subset\n",
    "            min_gini = gini\n",
    "\n",
    "    return best_feature, best_choice, best_threshold, best_left_subset, best_right_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(dataset, depth):\n",
    "    if len(dataset.iloc[:, -1].unique()) == 1:\n",
    "        return dataset.iloc[:, -1].unique()[0]\n",
    "    \n",
    "    feature, choice, threshold, left_subset, right_subset = choose_feature(dataset)\n",
    "    # 如果没有最佳特征，意味着所有特征都只有一类,投票决定该节点的类别。\n",
    "    if feature is None:\n",
    "        return dataset.iloc[:, -1].value_counts().index[0]\n",
    "    \n",
    "    # 递归地构建左右子树\n",
    "    left_tree = create_tree(left_subset, depth + 1)\n",
    "    right_tree = create_tree(right_subset, depth + 1)\n",
    "\n",
    "    return {\"feature\": feature, \"choice\": choice, \"threshold\": threshold, \"left\": left_tree, \"right\": right_tree}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用决策树进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tree(data, decision_tree):\n",
    "    if isinstance(decision_tree, str):\n",
    "        return decision_tree\n",
    "\n",
    "    if decision_tree[\"choice\"] is not None:\n",
    "        if data[decision_tree[\"feature\"]] == decision_tree[\"choice\"]:\n",
    "            return predict_tree(data, decision_tree[\"left\"])\n",
    "        else:\n",
    "            return predict_tree(data, decision_tree[\"right\"])\n",
    "    elif decision_tree[\"threshold\"] is not None:\n",
    "        if data[decision_tree[\"feature\"]] < decision_tree[\"threshold\"]:\n",
    "            return predict_tree(data, decision_tree[\"left\"])\n",
    "        else:\n",
    "            return predict_tree(data, decision_tree[\"right\"])\n",
    "    else:\n",
    "        raise Exception(\"存在既不是离散又不是连续的情况，出错！！！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tree(test_dataset, decision_tree):\n",
    "    predictions = test_dataset.apply(predict_tree, axis=1, args=(decision_tree,))\n",
    "    \n",
    "    # Assuming labels are categorical\n",
    "    labels = test_dataset.iloc[:, -1].unique()\n",
    "    \n",
    "    # Initialize counters for each class\n",
    "    true_positive = {label: 0 for label in labels}\n",
    "    true_negative = {label: 0 for label in labels}\n",
    "    false_positive = {label: 0 for label in labels}\n",
    "    false_negative = {label: 0 for label in labels}\n",
    "    \n",
    "    # Calculate counts for each class\n",
    "    for label in labels:\n",
    "        true_positive[label] = sum((predictions == label) & (test_dataset.iloc[:, -1] == label))\n",
    "        true_negative[label] = sum((predictions != label) & (test_dataset.iloc[:, -1] != label))\n",
    "        false_positive[label] = sum((predictions == label) & (test_dataset.iloc[:, -1] != label))\n",
    "        false_negative[label] = sum((predictions != label) & (test_dataset.iloc[:, -1] == label))\n",
    "    \n",
    "    # Calculate metrics for each class\n",
    "    accuracy = sum(true_positive.values()) / test_dataset.shape[0]\n",
    "    error_rate = (sum(false_negative.values()) + sum(false_positive.values())) / test_dataset.shape[0]\n",
    "    recall = {label: true_positive[label] / (true_positive[label] + false_negative[label]) for label in labels}\n",
    "    fpr = {label: false_positive[label] / (false_positive[label] + true_negative[label]) for label in labels}\n",
    "    tpr = {label: true_positive[label] / (true_positive[label] + false_negative[label]) for label in labels}\n",
    "    \n",
    "    return accuracy, error_rate, recall, fpr, tpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataset(dataset, num_sample):\n",
    "    samples = []\n",
    "    \n",
    "    # 随机选取数据和部分属性，选取的特征数量等于总特征数的平方根\n",
    "    num_feature = int(np.sqrt(dataset.shape[1]))\n",
    "\n",
    "    for i in range(num_sample):\n",
    "        # 对数据采样是有放回的，对于特征的采样是无放回的\n",
    "        sample = dataset.sample(dataset.shape[0], replace=True)\n",
    "        features = np.random.choice(sample.columns[:-1], num_feature, replace=False)\n",
    "        # 把数据和特征按行的方向拼接起来\n",
    "        sample = pd.concat([sample[features], sample.iloc[:, -1]], axis=1)\n",
    "\n",
    "        samples.append(sample)\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_forest(dataset, num_tree=20):\n",
    "    datas = sample_dataset(dataset, num_tree)\n",
    "    decision_trees = [create_tree(data, 1) for data in datas]\n",
    "    return decision_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_forest(data, forest):\n",
    "    y_lables = [predict_tree(data, tree) for tree in forest]\n",
    "    return max(set(y_lables), key=y_lables.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_forest(test_dataset, forest):\n",
    "    predictions = test_dataset.apply(predict_forest, axis=1, args=(random_forest,))\n",
    "    \n",
    "    # Assuming labels are categorical\n",
    "    labels = test_dataset.iloc[:, -1].unique()\n",
    "    \n",
    "    # Initialize counters for each class\n",
    "    true_positive = {label: 0 for label in labels}\n",
    "    true_negative = {label: 0 for label in labels}\n",
    "    false_positive = {label: 0 for label in labels}\n",
    "    false_negative = {label: 0 for label in labels}\n",
    "    \n",
    "    # Calculate counts for each class\n",
    "    for label in labels:\n",
    "        true_positive[label] = sum((predictions == label) & (test_dataset.iloc[:, -1] == label))\n",
    "        true_negative[label] = sum((predictions != label) & (test_dataset.iloc[:, -1] != label))\n",
    "        false_positive[label] = sum((predictions == label) & (test_dataset.iloc[:, -1] != label))\n",
    "        false_negative[label] = sum((predictions != label) & (test_dataset.iloc[:, -1] == label))\n",
    "    \n",
    "    # Calculate metrics for each class\n",
    "    accuracy = sum(true_positive.values()) / test_dataset.shape[0]\n",
    "    error_rate = (sum(false_negative.values()) + sum(false_positive.values())) / test_dataset.shape[0]\n",
    "    recall = {label: true_positive[label] / (true_positive[label] + false_negative[label]) for label in labels}\n",
    "    fpr = {label: false_positive[label] / (false_positive[label] + true_negative[label]) for label in labels}\n",
    "    tpr = {label: true_positive[label] / (true_positive[label] + false_negative[label]) for label in labels}\n",
    "    \n",
    "    return accuracy, error_rate, recall, fpr, tpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 带入数据进行验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "鸢尾花数据集上：\n",
      "----------------------------------------\n",
      "决策树准确率： 0.9666666666666667\n",
      "决策树错误率： 0.06666666666666667\n",
      "决策树召回率： {'Iris-versicolor': 1.0, 'Iris-setosa': 1.0, 'Iris-virginica': 0.875}\n",
      "决策树假正类率： {'Iris-versicolor': 0.0625, 'Iris-setosa': 0.0, 'Iris-virginica': 0.0}\n",
      "决策树真正类率： {'Iris-versicolor': 1.0, 'Iris-setosa': 1.0, 'Iris-virginica': 0.875}\n",
      "----------------------------------------\n",
      "随机森林准确率： 1.0\n",
      "随机森林错误率： 0.0\n",
      "随机森林召回率： {'Iris-versicolor': 1.0, 'Iris-setosa': 1.0, 'Iris-virginica': 1.0}\n",
      "随机森林假正类率： {'Iris-versicolor': 0.0, 'Iris-setosa': 0.0, 'Iris-virginica': 0.0}\n",
      "随机森林真正类率： {'Iris-versicolor': 1.0, 'Iris-setosa': 1.0, 'Iris-virginica': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"鸢尾花数据集上：\")\n",
    "train_dataset, test_dataset = iris_dataloader()\n",
    "decision_tree = create_tree(train_dataset, 1)\n",
    "\n",
    "print('-'*40)\n",
    "decision_tree_accuracy, decision_tree_error_rate, decision_tree_recall, decision_tree_fpr, decision_tree_tpr = test_tree(test_dataset, decision_tree)\n",
    "print(\"决策树准确率：\", decision_tree_accuracy)\n",
    "print(\"决策树错误率：\", decision_tree_error_rate)\n",
    "print(\"决策树召回率：\", decision_tree_recall)\n",
    "print(\"决策树假正类率：\", decision_tree_fpr)\n",
    "print(\"决策树真正类率：\", decision_tree_tpr)\n",
    "\n",
    "print('-'*40)\n",
    "random_forest = create_forest(train_dataset)\n",
    "random_forest_accuracy, random_forest_error_rate, random_forest_recall, random_forest_fpr, random_forest_tpr = test_forest(test_dataset, random_forest)\n",
    "print(\"随机森林准确率：\", random_forest_accuracy)\n",
    "print(\"随机森林错误率：\", random_forest_error_rate)\n",
    "print(\"随机森林召回率：\", random_forest_recall)\n",
    "print(\"随机森林假正类率：\", random_forest_fpr)\n",
    "print(\"随机森林真正类率：\", random_forest_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成人数据集上：\n",
      "决策树准确率： 0.7925\n",
      "决策树错误率： 0.415\n",
      "决策树召回率： {' <=50K': 0.853035143769968, ' >50K': 0.5747126436781609}\n",
      "决策树假正类率： {' <=50K': 0.42528735632183906, ' >50K': 0.14696485623003194}\n",
      "决策树真正类率： {' <=50K': 0.853035143769968, ' >50K': 0.5747126436781609}\n",
      "----------------------------------------\n",
      "随机森林准确率： 0.81\n",
      "随机森林错误率： 0.38\n",
      "随机森林召回率： {' <=50K': 0.9616613418530351, ' >50K': 0.26436781609195403}\n",
      "随机森林假正类率： {' <=50K': 0.735632183908046, ' >50K': 0.038338658146964855}\n",
      "随机森林真正类率： {' <=50K': 0.9616613418530351, ' >50K': 0.26436781609195403}\n"
     ]
    }
   ],
   "source": [
    "print(\"成人数据集上：\")\n",
    "train_dataset, test_dataset = adult_dataloader()\n",
    "decision_tree = create_tree(train_dataset, 1)\n",
    "decision_tree_accuracy, decision_tree_error_rate, decision_tree_recall, decision_tree_fpr, decision_tree_tpr = test_tree(test_dataset, decision_tree)\n",
    "print(\"决策树准确率：\", decision_tree_accuracy)\n",
    "print(\"决策树错误率：\", decision_tree_error_rate)\n",
    "print(\"决策树召回率：\", decision_tree_recall)\n",
    "print(\"决策树假正类率：\", decision_tree_fpr)\n",
    "print(\"决策树真正类率：\", decision_tree_tpr)\n",
    "\n",
    "print('-'*40)\n",
    "\n",
    "random_forest = create_forest(train_dataset)\n",
    "random_forest_accuracy, random_forest_error_rate, random_forest_recall, random_forest_fpr, random_forest_tpr = test_forest(test_dataset, random_forest)\n",
    "print(\"随机森林准确率：\", random_forest_accuracy)\n",
    "print(\"随机森林错误率：\", random_forest_error_rate)\n",
    "print(\"随机森林召回率：\", random_forest_recall)\n",
    "print(\"随机森林假正类率：\", random_forest_fpr)\n",
    "print(\"随机森林真正类率：\", random_forest_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
